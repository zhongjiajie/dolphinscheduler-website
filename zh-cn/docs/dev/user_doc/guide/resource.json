{
  "filename": "resource.md",
  "__html": "<h1>资源中心</h1>\n<p>如果需要用到资源上传功能，针对单机可以选择本地文件目录作为上传文件夹(此操作不需要部署 Hadoop)。当然也可以选择上传到 Hadoop or MinIO 集群上，此时则需要有Hadoop (2.6+) 或者 MinIO 等相关环境</p>\n<blockquote>\n<p><strong><em>注意:</em></strong></p>\n<ul>\n<li>如果用到资源上传的功能，那么 <a href=\"installation/standalone.md\">安装部署</a>中，部署用户需要有这部分的操作权限</li>\n<li>如果 Hadoop 集群的 NameNode 配置了 HA 的话，需要开启 HDFS 类型的资源上传，同时需要将 Hadoop 集群下的 <code>core-site.xml</code> 和 <code>hdfs-site.xml</code> 复制到 <code>/opt/dolphinscheduler/conf</code>，非 NameNode HA 跳过次步骤</li>\n</ul>\n</blockquote>\n<h2>hdfs资源配置</h2>\n<ul>\n<li>上传资源文件和udf函数，所有上传的文件和资源都会被存储到hdfs上，所以需要以下配置项：</li>\n</ul>\n<pre><code>conf/common.properties  \n    # Users who have permission to create directories under the HDFS root path\n    hdfs.root.user=hdfs\n    # data base dir, resource file will store to this hadoop hdfs path, self configuration, please make sure the directory exists on hdfs and have read write permissions。&quot;/dolphinscheduler&quot; is recommended\n    resource.upload.path=/dolphinscheduler\n    # resource storage type : HDFS,S3,NONE\n    resource.storage.type=HDFS\n    # whether kerberos starts\n    hadoop.security.authentication.startup.state=false\n    # java.security.krb5.conf path\n    java.security.krb5.conf.path=/opt/krb5.conf\n    # loginUserFromKeytab user\n    login.user.keytab.username=hdfs-mycluster@ESZ.COM\n    # loginUserFromKeytab path\n    login.user.keytab.path=/opt/hdfs.headless.keytab    \n    # if resource.storage.type is HDFS，and your Hadoop Cluster NameNode has HA enabled, you need to put core-site.xml and hdfs-site.xml in the installPath/conf directory. In this example, it is placed under /opt/soft/dolphinscheduler/conf, and configure the namenode cluster name; if the NameNode is not HA, modify it to a specific IP or host name.\n    # if resource.storage.type is S3，write S3 address，HA，for example ：s3a://dolphinscheduler，\n    # Note，s3 be sure to create the root directory /dolphinscheduler\n    fs.defaultFS=hdfs://mycluster:8020    \n    #resourcemanager ha note this need ips , this empty if single\n    yarn.resourcemanager.ha.rm.ids=192.168.xx.xx,192.168.xx.xx    \n    # If it is a single resourcemanager, you only need to configure one host name. If it is resourcemanager HA, the default configuration is fine\n    yarn.application.status.address=http://xxxx:8088/ws/v1/cluster/apps/%s\n\n</code></pre>\n<h2>文件管理</h2>\n<blockquote>\n<p>是对各种资源文件的管理，包括创建基本的 <code>txt/log/sh/conf/py/java</code> 等文件、上传jar包等各种类型文件，可进行编辑、重命名、下载、删除等操作。</p>\n</blockquote>\n<p><img src=\"/img/new_ui/dev/resource/file-manage.png\" alt=\"file-manage\"></p>\n<ul>\n<li>\n<p>创建文件</p>\n<blockquote>\n<p>文件格式支持以下几种类型：txt、log、sh、conf、cfg、py、java、sql、xml、hql、properties</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"/img/new_ui/dev/resource/create-file.png\" alt=\"create-file\"></p>\n<ul>\n<li>上传文件\n<blockquote>\n<p>上传文件：点击&quot;上传文件&quot;按钮进行上传，将文件拖拽到上传区域，文件名会自动以上传的文件名称补全</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"/img/new_ui/dev/resource/upload-file.png\" alt=\"upload-file\"></p>\n<ul>\n<li>\n<p>文件查看</p>\n<blockquote>\n<p>对可查看的文件类型，点击文件名称，可查看文件详情</p>\n</blockquote>\n  <p align=\"center\">\n      <img src=\"/img/file_detail.png\" width=\"80%\" />\n  </p>\n</li>\n<li>\n<p>下载文件</p>\n<blockquote>\n<p>点击文件列表的&quot;下载&quot;按钮下载文件或者在文件详情中点击右上角&quot;下载&quot;按钮下载文件</p>\n</blockquote>\n</li>\n<li>\n<p>文件重命名</p>\n</li>\n</ul>\n<p><img src=\"/img/new_ui/dev/resource/rename-file.png\" alt=\"rename-file\"></p>\n<ul>\n<li>删除</li>\n</ul>\n<blockquote>\n<p>文件列表-&gt;点击&quot;删除&quot;按钮，删除指定文件</p>\n</blockquote>\n<ul>\n<li>\n<p>重新上传文件</p>\n<blockquote>\n<p>点击文件列表中的”重新上传文件“按钮进行重新上传文件，将文件拖拽到上传区域，文件名会自动以上传的文件名称补全</p>\n</blockquote>\n  <p align=\"center\">\n    <img src=\"/img/reupload_file_en.png\" width=\"80%\" />\n  </p>\n</li>\n</ul>\n<h2>UDF管理</h2>\n<h3>资源管理</h3>\n<blockquote>\n<p>资源管理和文件管理功能类似，不同之处是资源管理是上传的UDF函数，文件管理上传的是用户程序，脚本及配置文件\n操作功能：重命名、下载、删除。</p>\n</blockquote>\n<ul>\n<li>\n<p>上传udf资源</p>\n<blockquote>\n<p>和上传文件相同。</p>\n</blockquote>\n</li>\n</ul>\n<h3>函数管理</h3>\n<ul>\n<li>\n<p>创建 UDF 函数</p>\n<blockquote>\n<p>点击“创建 UDF 函数”，输入 UDF 函数参数，选择udf资源，点击“提交”，创建udf函数。\n目前只支持HIVE的临时UDF函数</p>\n</blockquote>\n</li>\n</ul>\n<ul>\n<li>UDF 函数名称：输入UDF函数时的名称</li>\n<li>包名类名：输入UDF函数的全路径</li>\n<li>UDF 资源：设置创建的 UDF 对应的资源文件</li>\n</ul>\n<p><img src=\"/img/new_ui/dev/resource/create-udf.png\" alt=\"create-udf\"></p>\n<h2>任务组设置</h2>\n<p>任务组主要用于控制任务实例并发，旨在控制其他资源的压力（也可以控制Hadoop集群压力，不过集群会有队列管控）。您可在新建任务定义时，可配置对应的任务组，并配置任务在任务组内运行的优先级。</p>\n<h3>任务组配置</h3>\n<h4>新建任务组</h4>\n<p><img src=\"/img/new_ui/dev/resource/taskGroup.png\" alt=\"taskGroup\"></p>\n<p>用户点击【资源中心】-【任务组管理】-【任务组配置】-新建任务组</p>\n<p><img src=\"/img/new_ui/dev/resource/create-taskGroup.png\" alt=\"create-taskGroup\"></p>\n<p>您需要输入图片中信息，其中</p>\n<p>【任务组名称】：任务组在被使用时显示的名称</p>\n<p>【项目名称】：任务组作用的项目，该项为非必选项，如果不选择，则整个系统所有项目均可使用该任务组。</p>\n<p>【资源容量】：允许任务实例并发的最大数量</p>\n<h4>查看任务组队列</h4>\n<p><img src=\"/img/new_ui/dev/resource/view-queue.png\" alt=\"view-queue\"></p>\n<p>点击按钮查看任务组使用信息</p>\n<p><img src=\"/img/new_ui/dev/resource/view-groupQueue.png\" alt=\"view-queue\"></p>\n<h4>任务组的使用</h4>\n<p>注：任务组的使用适用于由 worker 执行的任务，例如【switch】节点、【condition】节点、【sub_process】等由 master 负责执行的节点类型不受任务组控制。</p>\n<p>我们以 shell 节点为例：</p>\n<p><img src=\"/img/new_ui/dev/resource/use-queue.png\" alt=\"use-queue\"></p>\n<p>关于任务组的配置，您需要做的只需要配置红色框内的部分，其中：</p>\n<p>【任务组名称】：任务组配置页面显示的任务组名称，这里只能看到该项目有权限的任务组（新建任务组时选择了该项目），或作用在全局的任务组（新建任务组时没有选择项目）</p>\n<p>【组内优先级】：在出现等待资源时，优先级高的任务会最先被 master 分发给 worker 执行，该部分数值越大，优先级越高。</p>\n<h3>任务组的实现逻辑</h3>\n<h4>获取任务组资源：</h4>\n<p>Master 在分发任务时判断该任务是否配置了任务组，如果任务没有配置，则正常抛给 worker 运行；如果配置了任务组，在抛给 worker 执行之前检查任务组资源池剩余大小是否满足当前任务运行，如果满足资源池 -1，继续运行；如果不满足则退出任务分发，等待其他任务结束唤醒。</p>\n<h4>释放与唤醒：</h4>\n<p>当获取到任务组资源的任务结束运行后，会释放任务组资源，释放后会检查当前任务组是否有任务等待，如果有则标记优先级最好的任务可以运行，并新建一个可以执行的event。该event中存储着被标记可以获取资源的任务id，随后在获取任务组资源然后运行。</p>\n<h4>任务组流程图</h4>\n<p align=\"center\">\n    <img src=\"/img/task_group_process.png\" width=\"80%\" />\n</p>        \n",
  "link": "/dist/zh-cn/docs/dev/user_doc/guide/resource.html",
  "meta": {}
}