{
  "filename": "configuration.md",
  "__html": "<!-- markdown-link-check-disable -->\n<h1>Configuration</h1>\n<h2>Preface</h2>\n<p>This document explains the DolphinScheduler application configurations according to DolphinScheduler-1.3.x versions.</p>\n<h2>Directory Structure</h2>\n<p>Currently, all the configuration files are under [conf ] directory.\nCheck the following simplified DolphinScheduler installation directories to have a direct view about the position of [conf] directory and configuration files it has.\nThis document only describes DolphinScheduler configurations and other topics are not going into.</p>\n<p>[Note: the DolphinScheduler (hereinafter called the ‘DS’) .]</p>\n<pre><code>├── LICENSE\n│\n├── NOTICE\n│\n├── licenses                                    directory of licenses\n│\n├── bin                                         directory of DolphinScheduler application commands, configrations scripts \n│   ├── dolphinscheduler-daemon.sh              script to start or shut down DolphinScheduler application\n│   ├── env                                     directory of scripts to load environment variables\n│   │   ├── dolphinscheduler_env.sh             script to export environment variables [eg: JAVA_HOME,HADOOP_HOME, HIVE_HOME ...] when you start or stop service using script `dolphinscheduler-daemon.sh`\n│   │   └── install_env.sh                      script to export environment variables for DolphinScheduler installation when you use scripts `install.sh` `start-all.sh` `stop-all.sh` `status-all.sh`\n│   ├── install.sh                              script to auto-setup services when you deploy DolphinScheduler in `psuedo-cluster` mode or `cluster` mode\n│   ├── remove-zk-node.sh                       script to cleanup ZooKeeper caches \n│   ├── scp-hosts.sh                            script to copy installation files to target hosts \n│   ├── start-all.sh                            script to start all services when you deploy DolphinScheduler in `psuedo-cluster` mode or `cluster` mode\n│   ├── status-all.sh                           script to check the status of all services when you deploy DolphinScheduler in `psuedo-cluster` mode or `cluster` mode\n│   └── stop-all.sh                             script to shut down all services when you deploy DolphinScheduler in `psuedo-cluster` mode or `cluster` mode\n│\n├── alert-server                                directory of DolphinScheduler alert-server commands, configrations scripts and libs\n│   ├── bin\n│   │   └── start.sh                            script to start DolphinScheduler alert-server\n│   ├── conf\n│   │   ├── application.yaml                    configurations of alert-server\n│   │   ├── common.properties                   configurations of common-service like storage, credentials, etc. \n│   │   ├── dolphinscheduler_env.sh             script to load environment variables for alert-server\n│   │   └── logback-spring.xml                  configurations of alert-service log\n│   └── libs                                    directory of alert-server libs\n│\n├── api-server                                  directory of DolphinScheduler api-server commands, configrations scripts and libs\n│   ├── bin\n│   │   └── start.sh                            script to start DolphinScheduler api-server\n│   ├── conf\n│   │   ├── application.yaml                    configurations of api-server\n│   │   ├── common.properties                   configurations of common-service like storage, credentials, etc.\n│   │   ├── dolphinscheduler_env.sh             script to load environment variables for api-server\n│   │   └── logback-spring.xml                  configurations of api-service log\n│   ├── libs                                    directory of api-server libs\n│   └── ui                                      directory of api-server related front-end web resources \n│\n├── master-server                               directory of DolphinScheduler master-server commands, configrations scripts and libs\n│   ├── bin                                \n│   │   └── start.sh                            script to start DolphinScheduler master-server\n│   ├── conf\n│   │   ├── application.yaml                    configurations of master-server\n│   │   ├── common.properties                   configurations of common-service like storage, credentials, etc.\n│   │   ├── dolphinscheduler_env.sh             script to load environment variables for master-server\n│   │   └── logback-spring.xml                  configurations of master-service log\n│   └── libs                                    directory of master-server libs\n│\n├── standalone-server                           directory of DolphinScheduler standalone-server commands, configrations scripts and libs\n│   ├── bin\n│   │   └── start.sh                            script to start DolphinScheduler standalone-server\n│   ├── conf\n│   │   ├── application.yaml                    configurations of standalone-server\n│   │   ├── common.properties                   configurations of common-service like storage, credentials, etc.\n│   │   ├── dolphinscheduler_env.sh             script to load environment variables for standalone-server\n│   │   ├── logback-spring.xml                  configurations of standalone-service log\n│   │   └── sql                                 .sql files to create or upgrade DolphinScheduler metadata\n│   ├── libs                                    directory of standalone-server libs\n│   └── ui                                      directory of standalone-server related front-end web resources\n│       \n├── tools                                       directory of DolphinScheduler metadata tools commands, configrations scripts and libs\n│   ├── bin\n│   │   └── upgrade-schema.sh                   script to initialize or upgrade DolphinScheduler metadata\n│   ├── conf\n│   │   ├── application.yaml                    configurations of tools\n│   │   └── common.properties                   configurations of common-service like storage, credentials, etc.\n│   ├── libs                                    directory of tool libs\n│   └── sql                                     .sql files to create or upgrade DolphinScheduler metadata\n│     \n├── worker-server                               directory of DolphinScheduler worker-server commands, configrations scripts and libs\n│       ├── bin\n│       │   └── start.sh                        script to start DolphinScheduler worker-server\n│       ├── conf\n│       │   ├── application.yaml                configurations of worker-server\n│       │   ├── common.properties               configurations of common-service like storage, credentials, etc.\n│       │   ├── dolphinscheduler_env.sh         script to load environment variables for worker-server\n│       │   └── logback-spring.xml              configurations of worker-service log\n│       └── libs                                directory of worker-server libs\n│\n└── ui                                          directory of front-end web resources\n</code></pre>\n<h2>Configurations in Details</h2>\n<table>\n<thead>\n<tr>\n<th>serial number</th>\n<th>service classification</th>\n<th>config file</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>startup or shutdown DS application</td>\n<td><a href=\"http://dolphinscheduler-daemon.sh\">dolphinscheduler-daemon.sh</a></td>\n</tr>\n<tr>\n<td>2</td>\n<td>datasource config properties</td>\n<td>datasource.properties</td>\n</tr>\n<tr>\n<td>3</td>\n<td>ZooKeeper config properties</td>\n<td>zookeeper.properties</td>\n</tr>\n<tr>\n<td>4</td>\n<td>common-service[storage] config properties</td>\n<td>common.properties</td>\n</tr>\n<tr>\n<td>5</td>\n<td>API-service config properties</td>\n<td>application-api.properties</td>\n</tr>\n<tr>\n<td>6</td>\n<td>master-service config properties</td>\n<td>master.properties</td>\n</tr>\n<tr>\n<td>7</td>\n<td>worker-service config properties</td>\n<td>worker.properties</td>\n</tr>\n<tr>\n<td>8</td>\n<td>alert-service config properties</td>\n<td>alert.properties</td>\n</tr>\n<tr>\n<td>9</td>\n<td>quartz config properties</td>\n<td>quartz.properties</td>\n</tr>\n<tr>\n<td>10</td>\n<td>DS environment variables configuration script[install/start DS]</td>\n<td>install_config.conf</td>\n</tr>\n<tr>\n<td>11</td>\n<td>load environment variables configs <br /> [eg: JAVA_HOME,HADOOP_HOME, HIVE_HOME ...]</td>\n<td>dolphinscheduler_env.sh</td>\n</tr>\n<tr>\n<td>12</td>\n<td>services log config files</td>\n<td>API-service log config : logback-api.xml  <br /> master-service log config  : logback-master.xml    <br /> worker-service log config : logback-worker.xml  <br /> alert-service log config : logback-alert.xml</td>\n</tr>\n</tbody>\n</table>\n<h3><a href=\"http://dolphinscheduler-daemon.sh\">dolphinscheduler-daemon.sh</a> [startup or shutdown DS application]</h3>\n<p><a href=\"http://dolphinscheduler-daemon.sh\">dolphinscheduler-daemon.sh</a> is responsible for DS startup and shutdown.\nEssentially, <a href=\"http://start-all.sh\">start-all.sh</a> or <a href=\"http://stop-all.sh\">stop-all.sh</a> startup and shutdown the cluster via <a href=\"http://dolphinscheduler-daemon.sh\">dolphinscheduler-daemon.sh</a>.\nCurrently, DS just makes a basic config, remember to config further JVM options based on your practical situation of resources.</p>\n<p>Default simplified parameters are:</p>\n<pre><code class=\"language-bash\"><span class=\"hljs-built_in\">export</span> DOLPHINSCHEDULER_OPTS=<span class=\"hljs-string\">&quot;\n-server \n-Xmx16g \n-Xms1g \n-Xss512k \n-XX:+UseConcMarkSweepGC \n-XX:+CMSParallelRemarkEnabled \n-XX:+UseFastAccessorMethods \n-XX:+UseCMSInitiatingOccupancyOnly \n-XX:CMSInitiatingOccupancyFraction=70\n&quot;</span>\n</code></pre>\n<blockquote>\n<p>&quot;-XX:DisableExplicitGC&quot; is not recommended due to may lead to memory link (DS dependent on Netty to communicate).</p>\n</blockquote>\n<h3>datasource.properties [datasource config properties]</h3>\n<p>DS uses Druid to manage database connections and default simplified configs are:</p>\n<table>\n<thead>\n<tr>\n<th>Parameters</th>\n<th>Default value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>spring.datasource.driver-class-name</td>\n<td></td>\n<td>datasource driver</td>\n</tr>\n<tr>\n<td>spring.datasource.url</td>\n<td></td>\n<td>datasource connection url</td>\n</tr>\n<tr>\n<td>spring.datasource.username</td>\n<td></td>\n<td>datasource username</td>\n</tr>\n<tr>\n<td>spring.datasource.password</td>\n<td></td>\n<td>datasource password</td>\n</tr>\n<tr>\n<td>spring.datasource.initialSize</td>\n<td>5</td>\n<td>initial connection pool size number</td>\n</tr>\n<tr>\n<td>spring.datasource.minIdle</td>\n<td>5</td>\n<td>minimum connection pool size number</td>\n</tr>\n<tr>\n<td>spring.datasource.maxActive</td>\n<td>5</td>\n<td>maximum connection pool size number</td>\n</tr>\n<tr>\n<td>spring.datasource.maxWait</td>\n<td>60000</td>\n<td>max wait milliseconds</td>\n</tr>\n<tr>\n<td>spring.datasource.timeBetweenEvictionRunsMillis</td>\n<td>60000</td>\n<td>idle connection check interval</td>\n</tr>\n<tr>\n<td>spring.datasource.timeBetweenConnectErrorMillis</td>\n<td>60000</td>\n<td>retry interval</td>\n</tr>\n<tr>\n<td>spring.datasource.minEvictableIdleTimeMillis</td>\n<td>300000</td>\n<td>connections over minEvictableIdleTimeMillis will be collect when idle check</td>\n</tr>\n<tr>\n<td>spring.datasource.validationQuery</td>\n<td>SELECT 1</td>\n<td>validate connection by running the SQL</td>\n</tr>\n<tr>\n<td>spring.datasource.validationQueryTimeout</td>\n<td>3</td>\n<td>validate connection timeout[seconds]</td>\n</tr>\n<tr>\n<td>spring.datasource.testWhileIdle</td>\n<td>true</td>\n<td>set whether the pool validates the allocated connection when a new connection request comes</td>\n</tr>\n<tr>\n<td>spring.datasource.testOnBorrow</td>\n<td>true</td>\n<td>validity check when the program requests a new connection</td>\n</tr>\n<tr>\n<td>spring.datasource.testOnReturn</td>\n<td>false</td>\n<td>validity check when the program recalls a connection</td>\n</tr>\n<tr>\n<td>spring.datasource.defaultAutoCommit</td>\n<td>true</td>\n<td>whether auto commit</td>\n</tr>\n<tr>\n<td>spring.datasource.keepAlive</td>\n<td>true</td>\n<td>runs validationQuery SQL to avoid the connection closed by pool when the connection idles over minEvictableIdleTimeMillis</td>\n</tr>\n<tr>\n<td>spring.datasource.poolPreparedStatements</td>\n<td>true</td>\n<td>open PSCache</td>\n</tr>\n<tr>\n<td>spring.datasource.maxPoolPreparedStatementPerConnectionSize</td>\n<td>20</td>\n<td>specify the size of PSCache on each connection</td>\n</tr>\n</tbody>\n</table>\n<h3>zookeeper.properties [zookeeper config properties]</h3>\n<table>\n<thead>\n<tr>\n<th>Parameters</th>\n<th>Default value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>zookeeper.quorum</td>\n<td>localhost:2181</td>\n<td>ZooKeeper cluster connection info</td>\n</tr>\n<tr>\n<td>zookeeper.dolphinscheduler.root</td>\n<td>/dolphinscheduler</td>\n<td>DS is stored under ZooKeeper root directory</td>\n</tr>\n<tr>\n<td>zookeeper.session.timeout</td>\n<td>60000</td>\n<td>session timeout</td>\n</tr>\n<tr>\n<td>zookeeper.connection.timeout</td>\n<td>30000</td>\n<td>connection timeout</td>\n</tr>\n<tr>\n<td>zookeeper.retry.base.sleep</td>\n<td>100</td>\n<td>time to wait between subsequent retries</td>\n</tr>\n<tr>\n<td>zookeeper.retry.max.sleep</td>\n<td>30000</td>\n<td>maximum time to wait between subsequent retries</td>\n</tr>\n<tr>\n<td>zookeeper.retry.maxtime</td>\n<td>10</td>\n<td>maximum retry times</td>\n</tr>\n</tbody>\n</table>\n<h3>common.properties [hadoop、s3、yarn config properties]</h3>\n<p>Currently, common.properties mainly configures Hadoop,s3a related configurations.</p>\n<table>\n<thead>\n<tr>\n<th>Parameters</th>\n<th>Default value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>data.basedir.path</td>\n<td>/tmp/dolphinscheduler</td>\n<td>local directory used to store temp files</td>\n</tr>\n<tr>\n<td>resource.storage.type</td>\n<td>NONE</td>\n<td>type of resource files: HDFS, S3, NONE</td>\n</tr>\n<tr>\n<td>resource.storage.upload.base.path</td>\n<td>/dolphinscheduler</td>\n<td>storage path of resource files</td>\n</tr>\n<tr>\n<td><a href=\"http://resource.aws.access.key.id\">resource.aws.access.key.id</a></td>\n<td>minioadmin</td>\n<td>access key id of S3</td>\n</tr>\n<tr>\n<td>resource.aws.secret.access.key</td>\n<td>minioadmin</td>\n<td>secret access key of S3</td>\n</tr>\n<tr>\n<td>resource.aws.region</td>\n<td>us-east-1</td>\n<td>region of S3</td>\n</tr>\n<tr>\n<td><a href=\"http://resource.aws.s3.bucket.name\">resource.aws.s3.bucket.name</a></td>\n<td>dolphinscheduler</td>\n<td>bucket name of S3</td>\n</tr>\n<tr>\n<td>resource.aws.s3.endpoint</td>\n<td><a href=\"http://minio:9000\">http://minio:9000</a></td>\n<td>endpoint of S3</td>\n</tr>\n<tr>\n<td>resource.hdfs.root.user</td>\n<td>hdfs</td>\n<td>configure users with corresponding permissions if storage type is HDFS</td>\n</tr>\n<tr>\n<td>resource.hdfs.fs.defaultFS</td>\n<td>hdfs://mycluster:8020</td>\n<td>If resource.storage.type=S3, then the request url would be similar to 's3a://dolphinscheduler'. Otherwise if resource.storage.type=HDFS and hadoop supports HA, copy core-site.xml and hdfs-site.xml into 'conf' directory</td>\n</tr>\n<tr>\n<td>hadoop.security.authentication.startup.state</td>\n<td>false</td>\n<td>whether hadoop grant kerberos permission</td>\n</tr>\n<tr>\n<td>java.security.krb5.conf.path</td>\n<td>/opt/krb5.conf</td>\n<td>kerberos config directory</td>\n</tr>\n<tr>\n<td>login.user.keytab.username</td>\n<td><a href=\"mailto:hdfs-mycluster@ESZ.COM\">hdfs-mycluster@ESZ.COM</a></td>\n<td>kerberos username</td>\n</tr>\n<tr>\n<td>login.user.keytab.path</td>\n<td>/opt/hdfs.headless.keytab</td>\n<td>kerberos user keytab</td>\n</tr>\n<tr>\n<td>kerberos.expire.time</td>\n<td>2</td>\n<td>kerberos expire time,integer,the unit is hour</td>\n</tr>\n<tr>\n<td>yarn.resourcemanager.ha.rm.ids</td>\n<td></td>\n<td>specify the yarn resourcemanager url. if resourcemanager supports HA, input HA IP addresses (separated by comma), or input null for standalone</td>\n</tr>\n<tr>\n<td>yarn.application.status.address</td>\n<td><a href=\"http://ds1:8088/ws/v1/cluster/apps/%25s\">http://ds1:8088/ws/v1/cluster/apps/%s</a></td>\n<td>keep default if ResourceManager supports HA or not use ResourceManager, or replace ds1 with corresponding hostname if ResourceManager in standalone mode</td>\n</tr>\n<tr>\n<td>dolphinscheduler.env.path</td>\n<td>env/dolphinscheduler_env.sh</td>\n<td>load environment variables configs [eg: JAVA_HOME,HADOOP_HOME, HIVE_HOME ...]</td>\n</tr>\n<tr>\n<td>development.state</td>\n<td>false</td>\n<td>specify whether in development state</td>\n</tr>\n<tr>\n<td>task.resource.limit.state</td>\n<td>false</td>\n<td>specify whether in resource limit state</td>\n</tr>\n</tbody>\n</table>\n<h3>application-api.properties [API-service log config]</h3>\n<table>\n<thead>\n<tr>\n<th>Parameters</th>\n<th>Default value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>server.port</td>\n<td>12345</td>\n<td>api service communication port</td>\n</tr>\n<tr>\n<td>server.servlet.session.timeout</td>\n<td>7200</td>\n<td>session timeout</td>\n</tr>\n<tr>\n<td>server.servlet.context-path</td>\n<td>/dolphinscheduler</td>\n<td>request path</td>\n</tr>\n<tr>\n<td>spring.servlet.multipart.max-file-size</td>\n<td>1024MB</td>\n<td>maximum file size</td>\n</tr>\n<tr>\n<td>spring.servlet.multipart.max-request-size</td>\n<td>1024MB</td>\n<td>maximum request size</td>\n</tr>\n<tr>\n<td>server.jetty.max-http-post-size</td>\n<td>5000000</td>\n<td>jetty maximum post size</td>\n</tr>\n<tr>\n<td>spring.messages.encoding</td>\n<td>UTF-8</td>\n<td>message encoding</td>\n</tr>\n<tr>\n<td>spring.jackson.time-zone</td>\n<td>GMT+8</td>\n<td>time zone</td>\n</tr>\n<tr>\n<td>spring.messages.basename</td>\n<td>i18n/messages</td>\n<td>i18n config</td>\n</tr>\n<tr>\n<td>security.authentication.type</td>\n<td>PASSWORD</td>\n<td>authentication type</td>\n</tr>\n<tr>\n<td>security.authentication.ldap.user.admin</td>\n<td>read-only-admin</td>\n<td>admin user account when you log-in with LDAP</td>\n</tr>\n<tr>\n<td>security.authentication.ldap.urls</td>\n<td>ldap://ldap.forumsys.com:389/</td>\n<td>LDAP urls</td>\n</tr>\n<tr>\n<td>security.authentication.ldap.base-dn</td>\n<td>dc=example,dc=com</td>\n<td>LDAP base dn</td>\n</tr>\n<tr>\n<td>security.authentication.ldap.username</td>\n<td>cn=read-only-admin,dc=example,dc=com</td>\n<td>LDAP username</td>\n</tr>\n<tr>\n<td>security.authentication.ldap.password</td>\n<td>password</td>\n<td>LDAP password</td>\n</tr>\n<tr>\n<td>security.authentication.ldap.user.identity-attribute</td>\n<td>uid</td>\n<td>LDAP user identity attribute</td>\n</tr>\n<tr>\n<td>security.authentication.ldap.user.email-attribute</td>\n<td>mail</td>\n<td>LDAP user email attribute</td>\n</tr>\n<tr>\n<td>security.authentication.ldap.user.not-exist-action</td>\n<td>CREATE</td>\n<td>action when LDAP user is not exist. Default CREATE: automatically create user when user not exist, DENY: deny log-in when user not exist</td>\n</tr>\n<tr>\n<td>traffic.control.global.switch</td>\n<td>false</td>\n<td>traffic control global switch</td>\n</tr>\n<tr>\n<td>traffic.control.max-global-qps-rate</td>\n<td>300</td>\n<td>global max request number per second</td>\n</tr>\n<tr>\n<td>traffic.control.tenant-switch</td>\n<td>false</td>\n<td>traffic control tenant switch</td>\n</tr>\n<tr>\n<td>traffic.control.default-tenant-qps-rate</td>\n<td>10</td>\n<td>default tenant max request number per second</td>\n</tr>\n<tr>\n<td>traffic.control.customize-tenant-qps-rate</td>\n<td></td>\n<td>customize tenant max request number per second</td>\n</tr>\n</tbody>\n</table>\n<h3>master.properties [master-service log config]</h3>\n<table>\n<thead>\n<tr>\n<th>Parameters</th>\n<th>Default value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>master.listen.port</td>\n<td>5678</td>\n<td>master listen port</td>\n</tr>\n<tr>\n<td>master.exec.threads</td>\n<td>100</td>\n<td>master-service execute thread number, used to limit the number of process instances in parallel</td>\n</tr>\n<tr>\n<td>master.exec.task.num</td>\n<td>20</td>\n<td>defines the number of parallel tasks for each process instance of the master-service</td>\n</tr>\n<tr>\n<td>master.dispatch.task.num</td>\n<td>3</td>\n<td>defines the number of dispatch tasks for each batch of the master-service</td>\n</tr>\n<tr>\n<td>master.host.selector</td>\n<td>LowerWeight</td>\n<td>master host selector, to select a suitable worker to run the task, optional value: random, round-robin, lower weight</td>\n</tr>\n<tr>\n<td>master.heartbeat.interval</td>\n<td>10</td>\n<td>master heartbeat interval, the unit is second</td>\n</tr>\n<tr>\n<td>master.task.commit.retryTimes</td>\n<td>5</td>\n<td>master commit task retry times</td>\n</tr>\n<tr>\n<td>master.task.commit.interval</td>\n<td>1000</td>\n<td>master commit task interval, the unit is millisecond</td>\n</tr>\n<tr>\n<td>master.max.cpuload.avg</td>\n<td>-1</td>\n<td>master max CPU load avg, only higher than the system CPU load average, master server can schedule. default value -1: the number of CPU cores * 2</td>\n</tr>\n<tr>\n<td>master.reserved.memory</td>\n<td>0.3</td>\n<td>master reserved memory, only lower than system available memory, master server can schedule. default value 0.3, the unit is G</td>\n</tr>\n</tbody>\n</table>\n<h3>worker.properties [worker-service log config]</h3>\n<table>\n<thead>\n<tr>\n<th>Parameters</th>\n<th>Default value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>worker.listen.port</td>\n<td>1234</td>\n<td>worker-service listen port</td>\n</tr>\n<tr>\n<td>worker.exec.threads</td>\n<td>100</td>\n<td>worker-service execute thread number, used to limit the number of task instances in parallel</td>\n</tr>\n<tr>\n<td>worker.heartbeat.interval</td>\n<td>10</td>\n<td>worker-service heartbeat interval, the unit is second</td>\n</tr>\n<tr>\n<td>worker.max.cpuload.avg</td>\n<td>-1</td>\n<td>worker max CPU load avg, only higher than the system CPU load average, worker server can be dispatched tasks. default value -1: the number of CPU cores * 2</td>\n</tr>\n<tr>\n<td>worker.reserved.memory</td>\n<td>0.3</td>\n<td>worker reserved memory, only lower than system available memory, worker server can be dispatched tasks. default value 0.3, the unit is G</td>\n</tr>\n<tr>\n<td>worker.groups</td>\n<td>default</td>\n<td>worker groups separated by comma, e.g., 'worker.groups=default,test' <br> worker will join corresponding group according to this config when startup</td>\n</tr>\n<tr>\n<td>worker.tenant.auto.create</td>\n<td>true</td>\n<td>tenant corresponds to the user of the system, which is used by the worker to submit the job. If system does not have this user, it will be automatically created after the parameter worker.tenant.auto.create is true.</td>\n</tr>\n<tr>\n<td>worker.tenant.distributed.user</td>\n<td>false</td>\n<td>Scenes to be used for distributed users.For example,users created by FreeIpa are stored in LDAP.This parameter only applies to Linux, When this parameter is true, worker.tenant.auto.create has no effect and will not automatically create tenants.</td>\n</tr>\n</tbody>\n</table>\n<h3>alert.properties [alert-service log config]</h3>\n<table>\n<thead>\n<tr>\n<th>Parameters</th>\n<th>Default value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>alert.type</td>\n<td>EMAIL</td>\n<td>alter type</td>\n</tr>\n<tr>\n<td>mail.protocol</td>\n<td>SMTP</td>\n<td>mail server protocol</td>\n</tr>\n<tr>\n<td>mail.server.host</td>\n<td><a href=\"http://xxx.xxx.com\">xxx.xxx.com</a></td>\n<td>mail server host</td>\n</tr>\n<tr>\n<td>mail.server.port</td>\n<td>25</td>\n<td>mail server port</td>\n</tr>\n<tr>\n<td>mail.sender</td>\n<td><a href=\"mailto:xxx@xxx.com\">xxx@xxx.com</a></td>\n<td>mail sender email</td>\n</tr>\n<tr>\n<td>mail.user</td>\n<td><a href=\"mailto:xxx@xxx.com\">xxx@xxx.com</a></td>\n<td>mail sender email name</td>\n</tr>\n<tr>\n<td>mail.passwd</td>\n<td>111111</td>\n<td>mail sender email password</td>\n</tr>\n<tr>\n<td>mail.smtp.starttls.enable</td>\n<td>true</td>\n<td>specify mail whether open tls</td>\n</tr>\n<tr>\n<td>mail.smtp.ssl.enable</td>\n<td>false</td>\n<td>specify mail whether open ssl</td>\n</tr>\n<tr>\n<td>mail.smtp.ssl.trust</td>\n<td><a href=\"http://xxx.xxx.com\">xxx.xxx.com</a></td>\n<td>specify mail ssl trust list</td>\n</tr>\n<tr>\n<td>xls.file.path</td>\n<td>/tmp/xls</td>\n<td>mail attachment temp storage directory</td>\n</tr>\n<tr>\n<td></td>\n<td>following configure WeCom[optional]</td>\n<td></td>\n</tr>\n<tr>\n<td>enterprise.wechat.enable</td>\n<td>false</td>\n<td>specify whether enable WeCom</td>\n</tr>\n<tr>\n<td><a href=\"http://enterprise.wechat.corp.id\">enterprise.wechat.corp.id</a></td>\n<td>xxxxxxx</td>\n<td>WeCom corp id</td>\n</tr>\n<tr>\n<td>enterprise.wechat.secret</td>\n<td>xxxxxxx</td>\n<td>WeCom secret</td>\n</tr>\n<tr>\n<td><a href=\"http://enterprise.wechat.agent.id\">enterprise.wechat.agent.id</a></td>\n<td>xxxxxxx</td>\n<td>WeCom agent id</td>\n</tr>\n<tr>\n<td>enterprise.wechat.users</td>\n<td>xxxxxxx</td>\n<td>WeCom users</td>\n</tr>\n<tr>\n<td>enterprise.wechat.token.url</td>\n<td><a href=\"https://qyapi.weixin.qq.com/cgi-bin/gettoken\">https://qyapi.weixin.qq.com/cgi-bin/gettoken</a>?  <br /> corpid=corpId&corpsecret=secret</td>\n<td>WeCom token url</td>\n</tr>\n<tr>\n<td>enterprise.wechat.push.url</td>\n<td><a href=\"https://qyapi.weixin.qq.com/cgi-bin/message/send\">https://qyapi.weixin.qq.com/cgi-bin/message/send</a>?  <br /> access_token=$token</td>\n<td>WeCom push url</td>\n</tr>\n<tr>\n<td>enterprise.wechat.user.send.msg</td>\n<td></td>\n<td>send message format</td>\n</tr>\n<tr>\n<td>enterprise.wechat.team.send.msg</td>\n<td></td>\n<td>group message format</td>\n</tr>\n<tr>\n<td>plugin.dir</td>\n<td>/Users/xx/your/path/to/plugin/dir</td>\n<td>plugin directory</td>\n</tr>\n</tbody>\n</table>\n<h3>quartz.properties [quartz config properties]</h3>\n<p>This part describes quartz configs and configure them based on your practical situation and resources.</p>\n<table>\n<thead>\n<tr>\n<th>Parameters</th>\n<th>Default value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>org.quartz.jobStore.driverDelegateClass</td>\n<td>org.quartz.impl.jdbcjobstore.StdJDBCDelegate</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.driverDelegateClass</td>\n<td>org.quartz.impl.jdbcjobstore.PostgreSQLDelegate</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.scheduler.instanceName</td>\n<td>DolphinScheduler</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.scheduler.instanceId</td>\n<td>AUTO</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.scheduler.makeSchedulerThreadDaemon</td>\n<td>true</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.useProperties</td>\n<td>false</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.threadPool.class</td>\n<td>org.quartz.simpl.SimpleThreadPool</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.threadPool.makeThreadsDaemons</td>\n<td>true</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.threadPool.threadCount</td>\n<td>25</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.threadPool.threadPriority</td>\n<td>5</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.class</td>\n<td>org.quartz.impl.jdbcjobstore.JobStoreTX</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.tablePrefix</td>\n<td>QRTZ_</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.isClustered</td>\n<td>true</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.misfireThreshold</td>\n<td>60000</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.clusterCheckinInterval</td>\n<td>5000</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.acquireTriggersWithinLock</td>\n<td>true</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.jobStore.dataSource</td>\n<td>myDs</td>\n<td></td>\n</tr>\n<tr>\n<td>org.quartz.dataSource.myDs.connectionProvider.class</td>\n<td>org.apache.dolphinscheduler.service.quartz.DruidConnectionProvider</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h3>install_config.conf [DS environment variables configuration script[install or start DS]]</h3>\n<p>install_config.conf is a bit complicated and is mainly used in the following two places.</p>\n<ul>\n<li>DS Cluster Auto Installation.</li>\n</ul>\n<blockquote>\n<p>System will load configs in the install_config.conf and auto-configure files below, based on the file content when executing '<a href=\"http://install.sh\">install.sh</a>'.\nFiles such as <a href=\"http://dolphinscheduler-daemon.sh\">dolphinscheduler-daemon.sh</a>, datasource.properties, zookeeper.properties, common.properties, application-api.properties, master.properties, worker.properties, alert.properties, quartz.properties, etc.</p>\n</blockquote>\n<ul>\n<li>Startup and Shutdown DS Cluster.</li>\n</ul>\n<blockquote>\n<p>The system will load masters, workers, alert-server, API-servers and other parameters inside the file to startup or shutdown DS cluster.</p>\n</blockquote>\n<h4>File Content</h4>\n<pre><code class=\"language-bash\">\n<span class=\"hljs-comment\"># Note:  please escape the character if the file contains special characters such as `.*[]^${}\\+?|()@#&amp;`.</span>\n<span class=\"hljs-comment\">#   eg: `[` escape to `\\[`</span>\n\n<span class=\"hljs-comment\"># Database type (DS currently only supports PostgreSQL and MySQL)</span>\ndbtype=<span class=\"hljs-string\">&quot;mysql&quot;</span>\n\n<span class=\"hljs-comment\"># Database url and port</span>\ndbhost=<span class=\"hljs-string\">&quot;192.168.xx.xx:3306&quot;</span>\n\n<span class=\"hljs-comment\"># Database name</span>\ndbname=<span class=\"hljs-string\">&quot;dolphinscheduler&quot;</span>\n\n\n<span class=\"hljs-comment\"># Database username</span>\nusername=<span class=\"hljs-string\">&quot;xx&quot;</span>\n\n<span class=\"hljs-comment\"># Database password</span>\npassword=<span class=\"hljs-string\">&quot;xx&quot;</span>\n\n<span class=\"hljs-comment\"># ZooKeeper url</span>\nzkQuorum=<span class=\"hljs-string\">&quot;192.168.xx.xx:2181,192.168.xx.xx:2181,192.168.xx.xx:2181&quot;</span>\n\n<span class=\"hljs-comment\"># DS installation path, such as &#x27;/data1_1T/dolphinscheduler&#x27;</span>\ninstallPath=<span class=\"hljs-string\">&quot;/data1_1T/dolphinscheduler&quot;</span>\n\n<span class=\"hljs-comment\"># Deployment user</span>\n<span class=\"hljs-comment\"># Note: Deployment user needs &#x27;sudo&#x27; privilege and has rights to operate HDFS.</span>\n<span class=\"hljs-comment\">#     Root directory must be created by the same user if using HDFS, otherwise permission related issues will be raised.</span>\ndeployUser=<span class=\"hljs-string\">&quot;dolphinscheduler&quot;</span>\n\n\n<span class=\"hljs-comment\"># Followings are alert-service configs</span>\n<span class=\"hljs-comment\"># Mail server host</span>\nmailServerHost=<span class=\"hljs-string\">&quot;smtp.exmail.qq.com&quot;</span>\n\n<span class=\"hljs-comment\"># Mail server port</span>\nmailServerPort=<span class=\"hljs-string\">&quot;25&quot;</span>\n\n<span class=\"hljs-comment\"># Mail sender</span>\nmailSender=<span class=\"hljs-string\">&quot;xxxxxxxxxx&quot;</span>\n\n<span class=\"hljs-comment\"># Mail user</span>\nmailUser=<span class=\"hljs-string\">&quot;xxxxxxxxxx&quot;</span>\n\n<span class=\"hljs-comment\"># Mail password</span>\nmailPassword=<span class=\"hljs-string\">&quot;xxxxxxxxxx&quot;</span>\n\n<span class=\"hljs-comment\"># Whether mail supports TLS</span>\nstarttlsEnable=<span class=\"hljs-string\">&quot;true&quot;</span>\n\n<span class=\"hljs-comment\"># Whether mail supports SSL. Note: starttlsEnable and sslEnable cannot both set true.</span>\nsslEnable=<span class=\"hljs-string\">&quot;false&quot;</span>\n\n<span class=\"hljs-comment\"># Mail server host, same as mailServerHost</span>\nsslTrust=<span class=\"hljs-string\">&quot;smtp.exmail.qq.com&quot;</span>\n\n<span class=\"hljs-comment\"># Specify which resource upload function to use for resources storage, such as sql files. And supported options are HDFS, S3 and NONE. HDFS for upload to HDFS and NONE for not using this function.</span>\nresourceStorageType=<span class=\"hljs-string\">&quot;NONE&quot;</span>\n\n<span class=\"hljs-comment\"># if S3, write S3 address. HA, for example: s3a://dolphinscheduler，</span>\n<span class=\"hljs-comment\"># Note: s3 make sure to create the root directory /dolphinscheduler</span>\ndefaultFS=<span class=\"hljs-string\">&quot;hdfs://mycluster:8020&quot;</span>\n\n<span class=\"hljs-comment\"># If parameter &#x27;resourceStorageType&#x27; is S3, following configs are needed:</span>\ns3Endpoint=<span class=\"hljs-string\">&quot;http://192.168.xx.xx:9010&quot;</span>\ns3AccessKey=<span class=\"hljs-string\">&quot;xxxxxxxxxx&quot;</span>\ns3SecretKey=<span class=\"hljs-string\">&quot;xxxxxxxxxx&quot;</span>\n\n<span class=\"hljs-comment\"># If ResourceManager supports HA, then input master and standby node IP or hostname, eg: &#x27;192.168.xx.xx,192.168.xx.xx&#x27;. Or else ResourceManager run in standalone mode, please set yarnHaIps=&quot;&quot; and &quot;&quot; for not using yarn.</span>\nyarnHaIps=<span class=\"hljs-string\">&quot;192.168.xx.xx,192.168.xx.xx&quot;</span>\n\n\n<span class=\"hljs-comment\"># If ResourceManager runs in standalone, then set ResourceManager node ip or hostname, or else remain default.</span>\nsingleYarnIp=<span class=\"hljs-string\">&quot;yarnIp1&quot;</span>\n\n<span class=\"hljs-comment\"># Storage path when using HDFS/S3</span>\nresourceUploadPath=<span class=\"hljs-string\">&quot;/dolphinscheduler&quot;</span>\n\n\n<span class=\"hljs-comment\"># HDFS/S3 root user</span>\nhdfsRootUser=<span class=\"hljs-string\">&quot;hdfs&quot;</span>\n\n<span class=\"hljs-comment\"># Followings are Kerberos configs</span>\n\n<span class=\"hljs-comment\"># Specify Kerberos enable or not</span>\nkerberosStartUp=<span class=\"hljs-string\">&quot;false&quot;</span>\n\n<span class=\"hljs-comment\"># Kdc krb5 config file path</span>\nkrb5ConfPath=<span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$installPath</span>/conf/krb5.conf&quot;</span>\n\n<span class=\"hljs-comment\"># Keytab username</span>\nkeytabUserName=<span class=\"hljs-string\">&quot;hdfs-mycluster@ESZ.COM&quot;</span>\n\n<span class=\"hljs-comment\"># Username keytab path</span>\nkeytabPath=<span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$installPath</span>/conf/hdfs.headless.keytab&quot;</span>\n\n\n<span class=\"hljs-comment\"># API-service port</span>\napiServerPort=<span class=\"hljs-string\">&quot;12345&quot;</span>\n\n\n<span class=\"hljs-comment\"># All hosts deploy DS</span>\nips=<span class=\"hljs-string\">&quot;ds1,ds2,ds3,ds4,ds5&quot;</span>\n\n<span class=\"hljs-comment\"># Ssh port, default 22</span>\nsshPort=<span class=\"hljs-string\">&quot;22&quot;</span>\n\n<span class=\"hljs-comment\"># Master service hosts</span>\nmasters=<span class=\"hljs-string\">&quot;ds1,ds2&quot;</span>\n\n<span class=\"hljs-comment\"># All hosts deploy worker service</span>\n<span class=\"hljs-comment\"># Note: Each worker needs to set a worker group name and default name is &quot;default&quot;</span>\nworkers=<span class=\"hljs-string\">&quot;ds1:default,ds2:default,ds3:default,ds4:default,ds5:default&quot;</span>\n\n<span class=\"hljs-comment\">#  Host deploy alert-service</span>\nalertServer=<span class=\"hljs-string\">&quot;ds3&quot;</span>\n\n<span class=\"hljs-comment\"># Host deploy API-service</span>\napiServers=<span class=\"hljs-string\">&quot;ds1&quot;</span>\n</code></pre>\n<h3>dolphinscheduler_env.sh [load environment variables configs]</h3>\n<p>When using shell to commit tasks, DolphinScheduler will export environment variables from <code>bin/env/dolphinscheduler_env.sh</code>. The\nmainly configuration including <code>JAVA_HOME</code>, mata database, registry center, and task configuration.</p>\n<pre><code class=\"language-bash\"><span class=\"hljs-comment\"># JAVA_HOME, will use it to start DolphinScheduler server</span>\n<span class=\"hljs-built_in\">export</span> JAVA_HOME=<span class=\"hljs-variable\">${JAVA_HOME:-/opt/soft/java}</span>\n\n<span class=\"hljs-comment\"># Database related configuration, set database type, username and password</span>\n<span class=\"hljs-built_in\">export</span> DATABASE=<span class=\"hljs-variable\">${DATABASE:-postgresql}</span>\n<span class=\"hljs-built_in\">export</span> SPRING_PROFILES_ACTIVE=<span class=\"hljs-variable\">${DATABASE}</span>\n<span class=\"hljs-built_in\">export</span> SPRING_DATASOURCE_URL\n<span class=\"hljs-built_in\">export</span> SPRING_DATASOURCE_USERNAME\n<span class=\"hljs-built_in\">export</span> SPRING_DATASOURCE_PASSWORD\n\n<span class=\"hljs-comment\"># DolphinScheduler server related configuration</span>\n<span class=\"hljs-built_in\">export</span> SPRING_CACHE_TYPE=<span class=\"hljs-variable\">${SPRING_CACHE_TYPE:-none}</span>\n<span class=\"hljs-built_in\">export</span> SPRING_JACKSON_TIME_ZONE=<span class=\"hljs-variable\">${SPRING_JACKSON_TIME_ZONE:-UTC}</span>\n<span class=\"hljs-built_in\">export</span> MASTER_FETCH_COMMAND_NUM=<span class=\"hljs-variable\">${MASTER_FETCH_COMMAND_NUM:-10}</span>\n\n<span class=\"hljs-comment\"># Registry center configuration, determines the type and link of the registry center</span>\n<span class=\"hljs-built_in\">export</span> REGISTRY_TYPE=<span class=\"hljs-variable\">${REGISTRY_TYPE:-zookeeper}</span>\n<span class=\"hljs-built_in\">export</span> REGISTRY_ZOOKEEPER_CONNECT_STRING=<span class=\"hljs-variable\">${REGISTRY_ZOOKEEPER_CONNECT_STRING:-localhost:2181}</span>\n\n<span class=\"hljs-comment\"># Tasks related configurations, need to change the configuration if you use the related tasks.</span>\n<span class=\"hljs-built_in\">export</span> HADOOP_HOME=<span class=\"hljs-variable\">${HADOOP_HOME:-/opt/soft/hadoop}</span>\n<span class=\"hljs-built_in\">export</span> HADOOP_CONF_DIR=<span class=\"hljs-variable\">${HADOOP_CONF_DIR:-/opt/soft/hadoop/etc/hadoop}</span>\n<span class=\"hljs-built_in\">export</span> SPARK_HOME1=<span class=\"hljs-variable\">${SPARK_HOME1:-/opt/soft/spark1}</span>\n<span class=\"hljs-built_in\">export</span> SPARK_HOME2=<span class=\"hljs-variable\">${SPARK_HOME2:-/opt/soft/spark2}</span>\n<span class=\"hljs-built_in\">export</span> PYTHON_HOME=<span class=\"hljs-variable\">${PYTHON_HOME:-/opt/soft/python}</span>\n<span class=\"hljs-built_in\">export</span> HIVE_HOME=<span class=\"hljs-variable\">${HIVE_HOME:-/opt/soft/hive}</span>\n<span class=\"hljs-built_in\">export</span> FLINK_HOME=<span class=\"hljs-variable\">${FLINK_HOME:-/opt/soft/flink}</span>\n<span class=\"hljs-built_in\">export</span> DATAX_HOME=<span class=\"hljs-variable\">${DATAX_HOME:-/opt/soft/datax}</span>\n\n<span class=\"hljs-built_in\">export</span> PATH=<span class=\"hljs-variable\">$HADOOP_HOME</span>/bin:<span class=\"hljs-variable\">$SPARK_HOME1</span>/bin:<span class=\"hljs-variable\">$SPARK_HOME2</span>/bin:<span class=\"hljs-variable\">$PYTHON_HOME</span>/bin:<span class=\"hljs-variable\">$JAVA_HOME</span>/bin:<span class=\"hljs-variable\">$HIVE_HOME</span>/bin:<span class=\"hljs-variable\">$FLINK_HOME</span>/bin:<span class=\"hljs-variable\">$DATAX_HOME</span>/bin:<span class=\"hljs-variable\">$PATH</span>\n</code></pre>\n<h3>Services logback configs</h3>\n<table>\n<thead>\n<tr>\n<th>Services name</th>\n<th>logback config name</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>API-service logback config</td>\n<td>logback-api.xml</td>\n</tr>\n<tr>\n<td>master-service logback config</td>\n<td>logback-master.xml</td>\n</tr>\n<tr>\n<td>worker-service logback config</td>\n<td>logback-worker.xml</td>\n</tr>\n<tr>\n<td>alert-service logback config</td>\n<td>logback-alert.xml</td>\n</tr>\n</tbody>\n</table>\n",
  "link": "/dist/en-us/docs/dev/user_doc/architecture/configuration.html",
  "meta": {}
}